{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the start of your adventure in Agentic AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Are you ready for action??</h2>\n",
    "            <span style=\"color:#ff7800;\">Have you completed all the setup steps in the <a href=\"../setup/\">setup</a> folder?<br/>\n",
    "            Have you checked out the guides in the <a href=\"../guides/01_intro.ipynb\">guides</a> folder?<br/>\n",
    "            Well in that case, you're ready!!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">This code is a live resource - keep an eye out for my updates</h2>\n",
    "            <span style=\"color:#00bfff;\">I push updates regularly. As people ask questions or have problems, I add more examples and improve explanations. As a result, the code below might not be identical to the videos, as I've added more steps and better comments. Consider this like an interactive book that accompanies the lectures.<br/><br/>\n",
    "            I try to send emails regularly with important updates related to the course. You can find this in the 'Announcements' section of Udemy in the left sidebar. You can also choose to receive my emails via your Notification Settings in Udemy. I'm respectful of your inbox and always try to add value with my emails!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And please do remember to contact me if I can help\n",
    "\n",
    "And I love to connect: https://www.linkedin.com/in/eddonner/\n",
    "\n",
    "\n",
    "### New to Notebooks like this one? Head over to the guides folder!\n",
    "\n",
    "Just to check you've already added the Python and Jupyter extensions to Cursor, if not already installed:\n",
    "- Open extensions (View >> extensions)\n",
    "- Search for python, and when the results show, click on the ms-python one, and Install it if not already installed\n",
    "- Search for jupyter, and when the results show, click on the Microsoft one, and Install it if not already installed  \n",
    "Then View >> Explorer to bring back the File Explorer.\n",
    "\n",
    "And then:\n",
    "1. Click where it says \"Select Kernel\" near the top right, and select the option called `.venv (Python 3.12.9)` or similar, which should be the first choice or the most prominent choice. You may need to choose \"Python Environments\" first.\n",
    "2. Click in each \"cell\" below, starting with the cell immediately below this text, and press Shift+Enter to run\n",
    "3. Enjoy!\n",
    "\n",
    "After you click \"Select Kernel\", if there is no option like `.venv (Python 3.12.9)` then please do the following:  \n",
    "1. On Mac: From the Cursor menu, choose Settings >> VS Code Settings (NOTE: be sure to select `VSCode Settings` not `Cursor Settings`);  \n",
    "On Windows PC: From the File menu, choose Preferences >> VS Code Settings(NOTE: be sure to select `VSCode Settings` not `Cursor Settings`)  \n",
    "2. In the Settings search bar, type \"venv\"  \n",
    "3. In the field \"Path to folder with a list of Virtual Environments\" put the path to the project root, like C:\\Users\\username\\projects\\agents (on a Windows PC) or /Users/username/projects/agents (on Mac or Linux).  \n",
    "And then try again.\n",
    "\n",
    "Having problems with missing Python versions in that list? Have you ever used Anaconda before? It might be interferring. Quit Cursor, bring up a new command line, and make sure that your Anaconda environment is deactivated:    \n",
    "`conda deactivate`  \n",
    "And if you still have any problems with conda and python versions, it's possible that you will need to run this too:  \n",
    "`conda config --set auto_activate_base false`  \n",
    "and then from within the Agents directory, you should be able to run `uv python list` and see the Python 3.12 version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's do an import\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next it's time to load the API keys into environment variables\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "# Check the keys\n",
    "\n",
    "import os\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set - please head to the troubleshooting guide in the setup folder\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - the all important import statement\n",
    "# If you get an import error - head over to troubleshooting guide\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we'll create an instance of the OpenAI class\n",
    "# If you're not sure what it means to create an instance of a class - head over to the guides folder!\n",
    "# If you get a NameError - head over to the guides folder to learn about NameErrors\n",
    "\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of messages in the familiar OpenAI format\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is 2+2?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 2 equals 4.\n"
     ]
    }
   ],
   "source": [
    "# And now call it! Any problems, head to the troubleshooting guide\n",
    "# This uses GPT 4.1 nano, the incredibly cheap model\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - let's ask for a question:\n",
    "\n",
    "question = \"Please propose a hard, challenging question to assess someone's IQ. Respond only with the question.\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If five machines take five minutes to make five widgets, how long would 100 machines take to make 100 widgets?\n"
     ]
    }
   ],
   "source": [
    "# ask it - this uses GPT 4.1 mini, still cheap but more powerful than nano\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "question = response.choices[0].message.content\n",
    "\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form a new messages list\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's analyze the problem step by step:\n",
      "\n",
      "**Given:**\n",
      "- 5 machines take 5 minutes to make 5 widgets.\n",
      "\n",
      "**Find:**\n",
      "- How long would 100 machines take to make 100 widgets?\n",
      "\n",
      "---\n",
      "\n",
      "**Step 1: Understand the production rate per machine.**\n",
      "\n",
      "Since 5 machines make 5 widgets in 5 minutes, the total output rate of all machines combined is:\n",
      "\n",
      "\\[\n",
      "\\text{5 widgets} / \\text{5 minutes} = 1\\ \\text{widget per minute (for all 5 machines)}\n",
      "\\]\n",
      "\n",
      "Therefore, the rate per machine is:\n",
      "\n",
      "\\[\n",
      "1\\ \\text{widget per minute (all machines)} \\div 5\\ \\text{machines} = \\frac{1}{5}\\ \\text{widget per minute per machine}\n",
      "\\]\n",
      "\n",
      "Each machine makes \\(\\frac{1}{5}\\) of a widget per minute.\n",
      "\n",
      "---\n",
      "\n",
      "**Step 2: Calculate how long it takes one machine to make one widget.**\n",
      "\n",
      "If in one minute, one machine makes \\(\\frac{1}{5}\\) of a widget, to make 1 whole widget, the machine would take:\n",
      "\n",
      "\\[\n",
      "1 \\div \\frac{1}{5} = 5\\ \\text{minutes}\n",
      "\\]\n",
      "\n",
      "So, each machine individually takes 5 minutes to make a widget.\n",
      "\n",
      "---\n",
      "\n",
      "**Step 3: Calculate time for 100 machines to make 100 widgets.**\n",
      "\n",
      "Since each machine takes 5 minutes for one widget, and machines work independently and simultaneously, 100 machines working together will each make one widget in 5 minutes.\n",
      "\n",
      "Therefore, 100 machines will make 100 widgets in:\n",
      "\n",
      "\\[\n",
      "\\boxed{5\\ \\text{minutes}}\n",
      "\\]\n",
      "\n",
      "---\n",
      "\n",
      "**Answer:**\n",
      "\n",
      "It would take **5 minutes** for 100 machines to make 100 widgets.\n"
     ]
    }
   ],
   "source": [
    "# Ask it again\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Let's analyze the problem step by step:\n",
       "\n",
       "**Given:**\n",
       "- 5 machines take 5 minutes to make 5 widgets.\n",
       "\n",
       "**Find:**\n",
       "- How long would 100 machines take to make 100 widgets?\n",
       "\n",
       "---\n",
       "\n",
       "**Step 1: Understand the production rate per machine.**\n",
       "\n",
       "Since 5 machines make 5 widgets in 5 minutes, the total output rate of all machines combined is:\n",
       "\n",
       "\\[\n",
       "\\text{5 widgets} / \\text{5 minutes} = 1\\ \\text{widget per minute (for all 5 machines)}\n",
       "\\]\n",
       "\n",
       "Therefore, the rate per machine is:\n",
       "\n",
       "\\[\n",
       "1\\ \\text{widget per minute (all machines)} \\div 5\\ \\text{machines} = \\frac{1}{5}\\ \\text{widget per minute per machine}\n",
       "\\]\n",
       "\n",
       "Each machine makes \\(\\frac{1}{5}\\) of a widget per minute.\n",
       "\n",
       "---\n",
       "\n",
       "**Step 2: Calculate how long it takes one machine to make one widget.**\n",
       "\n",
       "If in one minute, one machine makes \\(\\frac{1}{5}\\) of a widget, to make 1 whole widget, the machine would take:\n",
       "\n",
       "\\[\n",
       "1 \\div \\frac{1}{5} = 5\\ \\text{minutes}\n",
       "\\]\n",
       "\n",
       "So, each machine individually takes 5 minutes to make a widget.\n",
       "\n",
       "---\n",
       "\n",
       "**Step 3: Calculate time for 100 machines to make 100 widgets.**\n",
       "\n",
       "Since each machine takes 5 minutes for one widget, and machines work independently and simultaneously, 100 machines working together will each make one widget in 5 minutes.\n",
       "\n",
       "Therefore, 100 machines will make 100 widgets in:\n",
       "\n",
       "\\[\n",
       "\\boxed{5\\ \\text{minutes}}\n",
       "\\]\n",
       "\n",
       "---\n",
       "\n",
       "**Answer:**\n",
       "\n",
       "It would take **5 minutes** for 100 machines to make 100 widgets."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(answer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "That was a small, simple step in the direction of Agentic AI, with your new environment!\n",
    "\n",
    "Next time things get more interesting..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Now try this commercial application:<br/>\n",
    "            First ask the LLM to pick a business area that might be worth exploring for an Agentic AI opportunity.<br/>\n",
    "            Then ask the LLM to present a pain-point in that industry - something challenging that might be ripe for an Agentic solution.<br/>\n",
    "            Finally have 3 third LLM call propose the Agentic AI solution.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt the LLM to suggest a business area worth exploring for an Agentic AI opportunity.\n",
    "\n",
    "# Construct the initial message payload.\n",
    "messages = [{\"role\": \"user\", \"content\": \"Please propose a business area that may be worth exploring for an Agentic AI opportunity.\"}]\n",
    "\n",
    "# Call the chat completion endpoint with the business area prompt.\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "# Extract the LLM's suggested business area and store it in the `business_area` variable.\n",
    "business_area = response.choices[0].message.content\n",
    "print(business_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the LLM to identify a pain point in the business area—something challenging that might benefit from an Agentic AI solution.\n",
    "\n",
    "# Generate the pain-point prompt using the suggested business area.\n",
    "question = f\"Identify a pain-point in the {business_area} - something challenging that might be ripe for an Agentic solution.\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n",
    "\n",
    "# Call the chat completion endpoint with the pain-point prompt.\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "# Extract the LLM's identified pain point and store it in the `pain_point` variable.\n",
    "pain_point = response.choices[0].message.content\n",
    "print(pain_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have the LLM propose an Agentic AI solution to the identified pain-point in the selected business area.\n",
    "\n",
    "# Format the solution prompt using the previous pain point and business area.\n",
    "question = f\"Now, propose an Agentic AI solution to the pain-point {pain_point} in the {business_area} industry - something challenging that might be ripe for an Agentic solution.\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n",
    "\n",
    "# Call the chat completion endpoint with the solution prompt.\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "# Extract the LLM's proposed solution from the response content and store it in the `agentic_solution` variable.\n",
    "agentic_solution = response.choices[0].message.content\n",
    "print(agentic_solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
