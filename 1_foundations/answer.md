Let's analyze the problem step by step:

**Given:**
- 5 machines take 5 minutes to make 5 widgets.

**Find:**
- How long would 100 machines take to make 100 widgets?

---

**Step 1: Understand the production rate per machine.**

Since 5 machines make 5 widgets in 5 minutes, the total output rate of all machines combined is:

\[
\text{5 widgets} / \text{5 minutes} = 1\ \text{widget per minute (for all 5 machines)}
\]

Therefore, the rate per machine is:

\[
1\ \text{widget per minute (all machines)} \div 5\ \text{machines} = \frac{1}{5}\ \text{widget per minute per machine}
\]

Each machine makes \(\frac{1}{5}\) of a widget per minute.

---

**Step 2: Calculate how long it takes one machine to make one widget.**

If in one minute, one machine makes \(\frac{1}{5}\) of a widget, to make 1 whole widget, the machine would take:

\[
1 \div \frac{1}{5} = 5\ \text{minutes}
\]

So, each machine individually takes 5 minutes to make a widget.

---

**Step 3: Calculate time for 100 machines to make 100 widgets.**

Since each machine takes 5 minutes for one widget, and machines work independently and simultaneously, 100 machines working together will each make one widget in 5 minutes.

Therefore, 100 machines will make 100 widgets in:

\[
\boxed{5\ \text{minutes}}
\]

---

**Answer:**

It would take **5 minutes** for 100 machines to make 100 widgets.